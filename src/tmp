in recent years, the surge of big streaming data being available from sensors [12], social networks [17], and smart cities [3], has led to a shift of paradigms in data analytics throughout all disciplines.  instead of batch-oriented processing [8, 14, 15], stream-oriented data analytics [7] is becoming the gold standard. this has led to the development of scalable stream processing systems that implement the relational query model of relational data base management systems (rdbms) as continuous queries on event streams [2], and complex event processing systems that implement pattern matching on event streams [6].
query-driven stream processing, however, demands a domain expert to specify the analytics logic in a deterministic query language with a query that exactly denes which input events are transformed into which output events by an operator. however, an explicit specication is not always possible, as the domain expert might rather be interested in a more abstract query such as ‚Äúreport me all anomalies that molding machine 42 experiences on the shopoor.‚Äù in this example, it is infeasible to explicitly specify all event patterns that can be seen as an anomaly.
there have been dierent proposals how to deal with this issue.  ep-sparql employs background ontologies to empower (complex) event processing systems with stream reasoning [1] ‚Äì while focusing on the sparql query language. on the other hand, several general-purpose systems for stream processing exist such as apache kafka [11], apache flink [4], apache storm [19], apache spark streaming [22]. although these systems are powerful and generic, they are not tailored towards parallel and scalable incremental model training and inference on event streams.
at the same time, an increasing body of research addresses incremental (or online) updates of machine learning (ml) models: there are incremental algorithms for all kinds of ml techniques such as support vector machines [5], neural networks [9], or bayesian models [21]. clearly, a stream processing framework supporting intuitive integration of these algorithms would be highly benecial‚Äì saving the costs of hiring expensive ml experts to migrate these algorithms to the stream processing systems.

In this paper, we ask the question: how can we combine eventbased stream processing (e.g., for pattern recognition) with powerful Machine Learning functionality (e.g., to perform anomaly detection) in a way that is compatible with existing incremental ML algorithms? We propose the distributed event processing system StreamLearner that decouples expertise of Machine Learning from Distributed CEP using a general-purpose modular API. In particular, we provide the following contributions.

An architectural design and programming interface for data-parallel CEP that allows for easy integration of existing incremental ML algorithms (cf. Section 3).  ‚Ä¢ An algorithmic solution to the problems of incremental KMeans clustering and Markov model training in the context of anomaly detection in smart factories (cf. Section 4).  ‚Ä¢ An evaluation showing scalability of the StreamLearner architecture and throughput of up to 500 events per second using our algorithms for incremental ML model updates (cf. Section 5).

Machine Learning algorithms train a model using a given set of training data, e.g., building clusters, and then apply the trained model to solve problems, e.g., classifying unknown events. In the course of streaming data becoming available from sensors, models need to be dynamically adapted. That means, that new data is taken into account in the learned model, while old data ‚Äúfades out‚Äù and leaves the model as it becomes irrelevant. This can be modeled by a sliding window over the incoming event streams: Events within the window are relevant for the model training, whereas events that fall out of the window become irrelevant and should not be reected in the model any longer. Machine Learning on sliding windows is also known as non-stationary Machine Learning, i.e., the problem of keeping a model updated as the underlying streaming data generation‚Äúprocess‚Äù underlies a changing probability distribution. To adapt the ML model online, there are dierent possibilities. For instance, incremental algorithms change the model in a step-by-step fashion. The challenge in doing so is to support incremental processing
‚Äì i.e., streaming learning. The model should not be re-built from scratch for every new window, but rather incrementally be updated with new data while old data is removed.
Another challenge in ML in streaming data is that data from different streams might lead to independent models. For instance, data captured in one production machine might not be suitable to train the model of another production machine. The challenge is to determine which independent models shall be built based on which data from which incoming event streams. Further, the question is how to route the corresponding events to the appropriate model.
When these questions are solved, the identied machine learning models can be built in parallel ‚Äì enabling scalable, low-latency, and high-throughput stream processing.

3 STREAMLEARNER
In this section, we rst give an overview about the StreamLearner architecture, followed by a description of the easy-to-use API for incremental machine learning and situation inference models.
